# Техники тест-дизайна

## Что такое тест-дизайн и зачем он нужен?

В первую очередь они нужны, чтобы обеспечить требуемое тестовое покрытие

Основа для тест-дизайна - это оценка приоритетов, разных сочетаний условий, разных тестов и рисков обнаружения ошибок в них. Исходя из этой оценки мы выбираем те тестовые условия, которые мы можем себе позволить покрыть. Это должны быть либо условия с наибольшим приоритетом, то есть какие-то сценарии, которые для нашего пользователя важны или возникают с большей вероятностью, либо те тестовые условия, в которых невыполнение системой своих функций или некорректное выполнение несет наибольшие риски. Это не всегда синонимы потому, что могут быть ситуации, когда сценарий достаточно маловероятный и является не очень нужным пользователю, но, в случае если он не работает - это несет риск работоспособности системы. Таким образом нам нужно как-то выбрать, как нам покрыть требования и все остальные части нашего [базиса тестирования](%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D0%B0%D1%8F%20%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F%201c9ed51766e64318825fe2b29c761faa.md).

Это могут быть use case, какие-то описания бизнес-процессов, должностные инструкции пользователей разных ролей и тому подобные источники. Итак, во-первых, мы используем для тест-дизайна их все: покрываем тестами как правило требования, а остальные просто учитываем в том или ином виде, потому что контрактных обязательств по ним у нас как правило нет. Тем не менее, например для валидации системы учет дополнительных артефактов необходим, т.к. на основе требований валидацию мы провести не можем.

### Техники тестирования

![Screenshot 2022-05-11 140015.png](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Screenshot_2022-05-11_140015.png)

Различных техник тестирования существует великое множество. Их можно разделить на три категории

- Техники, базирующиеся на разного вида **спецификациях**. Это могут быть требования,
технические спецификации или артефакты, которые уже перечислялись ранее.
- Техники, базирующиеся на **структуре**. Это как правило методы белого ящика, то есть
покрытие операторов, ветвлений, множественных ветвлений и т.п.
- Техники, основанные на **опыте**. Это ситуации, когда у нас нет достаточной информации о внутренней структуре программы и нет требований или они не соответствуют критериям, предъявляемым к требованиям.

## Метод разбиения на классы эквивалентности (Equivalence class partitioning (ECP))

![Screenshot 2022-05-11 142606.png](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Screenshot_2022-05-11_142606.png)

Основная идея этого подхода - разделение множества входных значений на классы таким образом, чтобы для каждого класса мы ожидали одинаковую работу программы. В этой ситуации мы можем выбрать по одному из значений для каждого класса и протестировать на них, опираясь на то, что, если программа работает одинаково для этого класса, значит все остальные значения дают аналогичные результаты при работе программы. То есть мы выбираем одно любое значение и считаем, что оно представляет всю выборку.

### Что можно делить на классы эквивалентности?

В первую очередь мы делим на классы эквивалентности входные значения. То есть для определенной группы входных значений мы должны ожидать определенное поведения системы, для следующих групп другое поведение системы и так далее.

### Что нам может помочь разделить на классы эквивалентности правильно?

Мы можем рассматривать не только класс эквивалентности входных значений, но и классы эквивалентности выходных значений.

С одной стороны, это нам помогает перепроверить себя. То есть если мы видим, что для какого-то одного класса эквивалентности выходные значения можно разделить на два разных класса эквивалентности, то получается, что мы изначально неправильно выделили этот класс эквивалентности. Значит его нужно дробить на еще какие-то подмножества. При этом мы можем увидеть, что для некоторых разных классов эквивалентности у нас выходные значения попадают в один класс эквивалентности. Это означает, что возможно мы можем объединить эти классы эквивалентности и на этом сэкономить время на написание и проведение тестов

### В какой ситуации, для некоторых разных классов эквивалентности у нас выходные значения попадают в один класс эквивалентности?

Предположим, у вас есть какая-то форма с кучей валидаций для разных полей этой формы. Как правило, это очень тяжелый случай для применения классов эквивалентности, потому что возможных сочетаний значений очень много. Но при этом, если во всех негативных сценариях мы получаем одно и то же одинаковое для всех сообщение об ошибке, то сочетания возможных различных негативных сценариев нам проверять не надо.

То есть мы проверяем по отдельности каждый кейс с ошибкой, а вот сочетание полей с ошибкой проверять не стоит. Мы можем себе позволить на этом сэкономить, потому что выходной результат от этих сочетаний не зависит.

### Пример

У нас есть некая система, рассчитывающая сколько денег вернется, если отменить оплаченное
бронирование авиабилета. Для этого примера можно выделить 4 класса эквивалентности.

![Screenshot 2022-05-13 104101.png](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Screenshot_2022-05-13_104101.png)

Далее для каждого класса эквивалентности выбираем какое-то одно значение. Для выбранного значения проводим тест и сравниваем результат с ожидаемым.

![image_2022-05-13_10-45-05.png](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/image_2022-05-13_10-45-05.png)

### Сложность метода разбиения на классы

Сложная часть этого метода - это разделения на классы. А дальше метод применить достаточно просто. Но стоит заметить, что применение метода простое только в той ситуации, когда у вас есть числовая прямая. На ней можно сделать засечки и разделить все на классы эквивалентности. В реальной жизни таких входных параметров немного. Входные параметры могут быть разными.

В реальной жизни у нас очень редко бывают ситуации, когда мы обрабатываем один параметр, чаще мы проверяем совокупность нескольких параметров. И даже если у нас на форме есть только одно поле, важно понимать, что одно поле не равно один параметр.

Теперь давайте представим, что у вас несколько полей и по каждому такой же набор условий. Вы строите суперпозицию для этих полей и получается то, что называется комбинаторные взрыв, когда у вас количество тестов начинает уходить за любые разумные границы.

## Метод попарного тестирования (Pairwise testing)

![image_2022-05-13_11-25-21.png](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/image_2022-05-13_11-25-21.png)

Исследования выявили, что в большинстве случаев триггером для ошибки является комбинация одного или двух параметров значений. Вероятность того, что триггером ошибки является сочетание трех параметров, на порядки меньше. Соответственно отсюда и появилась идея попарного тестирования.

Идея в том, что если рассмотреть все возможные пары входных параметров при каких-то валидных значениях остальных параметров, то таким образом мы покроем достаточное количество тестовых случаев, чтобы считать, что тестирование достаточно глубокое и хорошее и мы не упускаем высоковероятный сценарий с высоко приоритетными ошибками.

![Screenshot 2022-05-13 123658.png](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Screenshot_2022-05-13_123658.png)

Таблица показывает количество ошибок для двух тестовых систем, зависящих от: 1-ая строка - от двух параметров, 2-ая строка - от трёх параметров и так далее. Мы видим, что различие достаточно существенное

### Пример

У нас есть фонарик в смартфоне и работает он по правилам, которые указаны на слайде:

- приложение работает под Android или iOS;
- у него есть 3 режима яркости;
- умеет гореть постоянно или мигать.

Ниже представлен набор тестов, которые мы получим методом эквивалентного разбиения для этого случая (левая таблица) и набор тестов, которые мы получим методом попарного тестирования, т.е сочетание всех возможных пар (правая таблица).

![Untitled](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Untitled.png)

В данном случае у нас всего три параметра, поэтому различия не радикальны, но тем не менее разница почти в 2 раза. Соответственно, чем больше у нас параметров, тем больше будет разница между количеством тестов, проходящих все возможные сочетания, и количеством тестов, полученных методом Pairwise.

### Преимущества и недостатки метода попарного тестирования

В качестве преимущества мы получаем лучшее соотношение количества тестов к количеству багов. То есть количество тестов необходимых для того, чтобы найти хотя бы один баг, у нас уменьшается и общее количество тест-кейсов тоже уменьшается. Соответственно мы экономим время и бюджет проекта.

При этом мы можем упустить какие-то сложные кейсы, которые всё-таки появятся в production. То есть необходимо понимать, что любое снижение количества тестов автоматически означает повышение рисков появления багов. Исчерпывающее тестирование невозможно, значит все равно останется что-то не протестированное, значит все равно баги в системе будут. Всё что мы можем, это минимизировать вероятность того, что пользователь на них наткнется.

И второй недостаток - чувствительность к выбору корректных значений, которые мы потом будем попарно тестировать. Если выбор не корректный, то как и с методом эквивалентных разбиений результат получится достаточно скромным.

### Область применения

Одно время метод попарного тестирования был очень популярным. Сейчас его наконец начали использовать меньше и в основном в тех случаях, когда его правда нужно использовать.

Это не универсальный метод. В нем точно также как и в методе эквивалентных разбиений важно правильно собрать наборы параметров. По своей сути Pairwise чаще всего основывается на тех же классах эквивалентности, что и метод эквивалентных разбиений, с теми же сложностями правильного выбора классов эквивалентности.

Раньше метод попарного тестирования, был достаточно сложен в применении из-за отсутствия инструментов, для построения таблиц. Сейчас же этих инструментов полно:

- [PICT](https://github.com/microsoft/pict) - pairwise Independent Combinatorial Testing', provided by Microsoft Corp;
- [IBM FoCuS](https://researcher.watson.ibm.com/researcher/view_group.php?id=1871) - 'Functional Coverage Unified Solution', provided by IBM;
- [ACTS](https://csrc.nist.rip/groups/SNS/acts/documents/comparison-report.html) - 'Advanced Combinatorial Testing System', provided by NIST, an agency of the US Govemment;
- [Hexawise](https://hexawise.com/);
- [Jenny](http://www.testingtoolsguide.net/tools/jenny/);
- [Pairwise by Inductive AS](https://inductive.no/pairwiser/);
- [VPTag free All-Pair Testing Tool](http://pairwisetesting.com/tools.html).

## Анализ граничных значений (Boundary Value Analysis)

![Untitled](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Untitled%201.png)

Метод появился из простого наблюдения, что на границах классов эквивалентности баги возникают существенно чаще, чем на значениях из середины класса, если мы берем некое последовательное множество.

Почему так? Потому что программисты и аналитики могут перепутать знаки, например вместо знака `<` поставить знак `>`. Потому что достаточно много краевых условий заложено в алгоритмы, которыми мы пользуемся, когда берем их из сторонних библиотек и трудно уследить за ними всеми.

Соответственно это повышает вероятность ошибок в каких-то пограничных ситуациях и означает, что довольно эффективно находить ошибки мы будем, тестируя граничные значения.

### Принцип применения

Метод анализ граничных значений основывается на эквивалентных разбиениях и предполагает, что мы тестируем границы классов эквивалентности и, как часто формулируется в разных учебниках, соседние с ними значения. Что такое соседние значения?

![Untitled](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Untitled%202.png)

Мы тестируем граничные значения и соседние с ним, лежащие за пределами классы эквивалентности. Анализ граничных значений опирается на метод эквивалентных разбиении, и мы хотим покрыть классы эквивалентности. То есть мы берём граничные значения и соседнее значение с той стороны, где мы переходим через границу классов эквивалентности и уже попадаем в другой класс.

Тестирование, когда мы берём значение в обе стороны - это более простой подход, но оно избыточное. Если у вас таких кейсов лишних получается десять, то ладно, но если их сто, то это становится существенно. Поэтому в каких-то мелких частных случаях можно позволить себе избыточное тестирование. Такое избыточное тестирование называется проверкой [робастности](%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D0%B0%D1%8F%20%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F%201c9ed51766e64318825fe2b29c761faa.md) - проверкой устойчивости системы. Она не всегда нужна, но иногда проще написать эту пару лишних кейсов, чем вообще задуматься, нужна она или нет. Потому что пара лишних кейсов в случае, когда их у вас несколько сотен - это не очень много. А вот когда количество таких кейсов становится большим, разница более существенная, и важно выбирать граничные значения правильно.

### Общий алгоритм работы с анализом граничных значений

![Untitled](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Untitled%203.png)

Обратите внимание на второй шаг, где мы выбрали классы эквивалентности. В методе эквивалентных разбиений `>` или `>=` нас не интересовали, а здесь они начинают нас интересовать. И очень часто уже на этом этапе, даже не начав писать тест кейсы, мы оформляем баги и идем с ними к аналитикам, потому что в ТЗ не написано, как должно быть правильно

### Пример на числовой прямой

Рассмотрим [ранее обозначенный пример с возвратом денег при отмене авиабилетов](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815.md).

И рассмотрим, сколько же нам нужно отступить от границы? Один день? Час? Минута? Какое значение будет соседнее?

![Untitled](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Untitled%204.png)

В идеале мы опираемся на соседнее значение с точки зрения того, как данные хранятся. То есть, если у нас данные хранятся в секундах и обрабатываются в секундах, то мы берём как интервал - секунду, если в минутах соответственно берём интервал - минуту. Потому что на интервале в полчаса, если данные хранятся в секундах, то ошибку `>` или `>=` мы не поймаем.

Если у нас данные хранятся и обрабатываются в секундах, а в интерфейсе вводятся в минутах, например, то мы технически не можем задать такие значения и берём те которые можем. То есть мы берём минимальный шаг, который можем себе позволить.

А если у нас входной параметр это некое число с плавающей точкой с бесконечным количеством знаков после запятой? У нас никогда не будет поля в интерфейсе, где мы сможем ввести бесконечное количество знаков после запятой. Там всегда будет ограничение.

Мы опираемся на это ограничение и берём ближайшее соседнее значение, которое можем ввести. Если мы тестируем API, то мы можем ввести любое достаточно малое значение.

### Что если у используется не числовая прямая?

На картинке ниже представлены и описаны некоторые примеры границ. Самый красивый пример - с датами, потому что там одно маленькое поле, а граничных значений полно.

![Untitled](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Untitled%205.png)

Довольно интересными являются границы структур данных, то есть если у вас вводится некое число и в требованиях нет ограничений на значение этого числа (в любом случае ограничение типа присутствует).

Надо или не надо его тестировать? Приоритетны такие цели или не очень?

Это отдельный вопрос, но технически - это граничное значение и в любом случае тут будет какое-то неожиданное поведение. Границы конфигураций тоже достаточно интересная тема, как и тестирование конфигураций.

Например, у вас в системе есть какие-то настройки, в которой вы инсталлируйте систему и у вас есть какой-то набор настроек у инсталлятора. Может быть достаточно большое количество корнер кейсов, то есть граничных условий:

- по занимаемой памяти;
- по настройкам системы;
- по значениям параметров.

Даже если возьмем операционную систему Windows - в ней есть ограничение на длину адреса, длиннее которого адрес быть не может.

Есть и более сложные случаи. Например, у вас есть какой-то клиент-серверное приложение и у сервера есть конфигурационный файл. Какие параметры в нем возможны и допустимы? В принципе, если это интернет-магазин, который устанавливается один раз, разворачивается на сервере и дальше в таком виде живёт, то это тестировать не обязательно.

Если же, например, вы пишете какую-то свою СУБД, то предполагается, что её будут пытаться поставить на свою локальную машину студенты, школьники, да кто угодно. И вот тогда подобные вещи становятся важными. А какие значения параметров конфигурации можно задать? Какое значение количества памяти на одно подключение к базе данных? Когда это число совсем не адекватное, важно чтобы система даже не поднялась, потому что работать она нормально всё равно не сможет.

То есть количество таких возможных кейсов будет тем больше, чем более сложную конфигурацию имеет ваша система, и чем большее число параметров вы предоставляете своим пользователям для настройки и для регулирования.

### Пример с мобильным приложением (не на числовой прямой)

Рассмотрим пример с мобильным приложением, которое вы должны тестировать на разных девайсах. Это самый частый и самый очевидный кейс, применения метода граничных значений.

![Untitled](%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%82%D0%B5%D1%81%D1%82-%D0%B4%D0%B8%D0%B7%D0%B0%D0%B8%CC%86%D0%BD%D0%B0%20e4feda79115943c191f7264c29362815/Untitled%206.png)

Самая очевидная вещь: на каких версиях Android вы будете тестировать мобильное приложение? Как правило, у нас есть минимальная версия, которую мы должны поддерживать, соответственно мы точно тестируем на ней и на последней версии. Это и есть граничные значения. Проводить тестирование на всех поддерживаемых версиях может оказаться слишком дорого. Как правило, количество конфигурационных тестов для каждой из версии - весьма заметное. То есть на каждую версию у вас уйдет полчаса-час. Бывают приложения, где конфигурационное тестирование более сложное. Тут все зависит от того насколько сложное приложение и насколько оно зависимо от ресурсов системы.

Если у вас такой большой разбег по версиям, то имеет смысл применить метод эквивалентных разбиений, а не анализ граничных значений отдельно от него. И понять, что в той части, которая нас интересует, SDK менялась столько-то раз. Помимо крайних версий мы получим два класса промежуточных, в которых поведение операционной системы отличается и от младшей версии и, от старшей версии. И тогда мы берём по одной версии операционной системы из промежуточных.

Тоже самое касается тестирования девайсов, которые написаны на Андроиде. Если кто не знает, то операционная система Android как таковая не существует - это огромный зоопарк операционных систем в рамках одной базовой версии, для которой каждый производитель девайсов что-нибудь своё изобретает. То, что смастерил какой-нибудь скажем китайский производитель телефонов, вполне может заставить вас предложения сломаться. Как правило китайские производители часто перестают поддерживать свою операционную систему очень быстро. К примеру, год поддерживают, а затем прекращают. Это означает, что часть пользователей, которые раз в год телефоны не меняют, останутся со старыми версиями систем. И если вы ориентируетесь на эту целевую аудиторию, то эти граничные значения у вас появляются условно новые, даже когда вы опираетесь просто на статистику использования телефонов.

Телефонов существует огромное количество, разных по своим параметрам, например по размерам экранов, разрешению экранов. Что делаем в таком случае? Точно также мы берём минимально поддерживаемые разрешения, которое оно должно быть указано в требованиях. Это тоже существенный момент, который должен учитываться при тестировании требований. Причем учитываться при тестировании требований как к мобильному приложению, так и к веб и к десктопным приложениям. Хоть в десктопах нет такого зоопарка экранов, но там есть волшебная возможность уменьшать и увеличивать окошко. Вот поэтому минимальное поддерживаемое разрешение обязательно учитываем. Размер экрана и разрешение экрана очевидно связаны, но как раз для телефонов у нас могут возникать интересные ситуации, когда у нас размер маленький, а разрешение 4К. И вот такие кейсы тоже лучше тестировать. То есть минимальный размер с максимально возможным для этого размера разрешением. Что касается верхней границы, то тут всё несколько сложнее. Потому что, во-первых, у вас не всегда будет доступен максимальный размер экрана. А, во-вторых, вы можете начать тестирование сегодня, а через месяц появится девайс с экраном или с разрешением большим, чем вы взяли. Но на самом деле максимальный размер вам не нужен, вам нужен достаточно большой размер экран. Потому что баги вёрстки, которые мы в этой ситуации ловим, будут возникать на любом достаточно большом экране. С появлением экранов 4К все подобные эффекты стали заметны. Если кто-то себе покупал подобный девайс, то наверняка натыкался на неудобную верстку, которая рассчитана под стандартное разрешение. В таком случаем происходило следующее - на экране много места, а кнопки на экране крошечные, буквы совершенно крошечные, попасть в это невозможно. Эта проблема актуальна не только для мобильных устройств, но на мобильных устройствах появляется гораздо чаще.

Ещё один параметр, к которому анализ граничных значений мы всегда применяем - это тестирование систем с разными ресурсами. Если вы разрабатываете приложение чувствительное к ресурсам, например игру. Для игры у вас обязаны быть минимальные системные требования, то есть минимальный объем оперативной памяти, процессора и т.д. И естественно на этой минимальной конфигурации вы проводите тестирование. Здесь же встает тонкий вопрос тестирования производительности: какие ещё конфигурации вас будут интересовать? Если в принципе кроме минимальных системных требований никаких других различий на разных ресурсах для системы нет, то тестирования минимальных и каких-то более или менее стандартных будет достаточно. Но Performance тестеры очень часто находят всякое интересное на каких-нибудь промежуточных вариантах, потому что там подобные ошибки часто вылезают. Бывают игры, которые подстраиваются под ресурс компьютера, например графику чуть-чуть упрощают, если у вас не хватает ресурсов в полном объеме для ее использования, еще какие-то оптимизации и упрощения делают. И эти кейсы стоит проверять, но это уже не про анализ граничных значений. Про анализ граничных значений - это то, что мы всегда тестируем минимальное. В данном случае, в случае с ресурсами, максимальное тестировать не надо, так как это не актуально.